{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec17-1",
   "metadata": {},
   "source": [
    "## Lecture 17 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion questions ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: the results of 400 tosses of a coin </br>\n",
    "Question (a) ●“This coin is fair.”</br>\n",
    "             ● “No, it’s not.”</br>\n",
    "Question (b) ●“This coin is fair.”</br>\n",
    "             ● “No, it’s biased towards heads.”</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = make_array(0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated = sample_proportions(400, coins)\n",
    "simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_coin(size):\n",
    "    return sample_proportions(size, coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_result = make_array()\n",
    "tail_result = make_array()\n",
    "coin_time = 10000\n",
    "for i in np.arange(coin_time):\n",
    "   \n",
    "    new_head = simulate_coin(400).item(0)\n",
    "    new_tail = 1 - new_head\n",
    "    head_result = np.append(head_result, new_head)\n",
    "    tail_result = np.append(tail_result, new_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem (a)\n",
    "# check how far the simulation result from the 50% (fair chance of head)\n",
    "Table().with_column('the discrepency of head - 50%', abs(head_result - 0.5)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem (b)\n",
    "# check if the simulation with the head_result close to 50% (fair chance of head)\n",
    "Table().with_column('head %', head_result).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem (b)\n",
    "# check the difference between heads and tails (if heads - tails > 0 which is favor to head)\n",
    "# the result is pretty identical to the previous cell\n",
    "Table().with_column('the difference between heads and tails (heads - tails)', head_result - tail_result).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alameda County Jury Panels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury = Table().with_columns(\n",
    "    'Ethnicity', make_array('Asian', 'Black', 'Latino', 'White', 'Other'),\n",
    "    'Eligible', make_array(0.15, 0.18, 0.12, 0.54, 0.01),\n",
    "    'Panels', make_array(0.26, 0.08, 0.08, 0.54, 0.04)\n",
    ")\n",
    "\n",
    "jury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under the model, this is the true distribution of people\n",
    "# from which the jurors are randomly sampled\n",
    "model = make_array(0.15, 0.18, 0.12, 0.54, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's simulate a random draw of 1423 jurors from this distribution\n",
    "simulated = sample_proportions(1423, model)\n",
    "simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual observed distribution (Panels) looks quite different\n",
    "# from the simulation -- try running this several times to confirm!\n",
    "jury_with_simulated = jury.with_column('Simulated', simulated)\n",
    "jury_with_simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_with_simulated.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec17-9",
   "metadata": {},
   "source": [
    "## Distance Between Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the last lecture, the difference between observed black/purple\n",
    "# and their expected values (26%/75%) was our statistic.\n",
    "#\n",
    "# In this case, we need to understand how each of the 5 categories\n",
    "# differ from their expected values according to the model.\n",
    "\n",
    "diffs = jury.column('Panels') - jury.column('Eligible')\n",
    "jury_with_difference = jury.with_column('Difference', diffs)\n",
    "jury_with_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-lec17-11",
   "metadata": {},
   "source": [
    "## Total Variation Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvd(dist1, dist2):\n",
    "    return sum(abs(dist1 - dist2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TVD of our observed data (Panels) from their expected values\n",
    "# assuming the model is true (Eligbible)\n",
    "obsvd_tvd = tvd(jury.column('Panels'), jury.column('Eligible'))\n",
    "obsvd_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TVD of a model simluation from its expected values\n",
    "tvd(sample_proportions(1423, model), jury.column('Eligible'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_tvd():\n",
    "    return tvd(sample_proportions(1423, model), model)\n",
    "\n",
    "tvds = make_array()\n",
    "\n",
    "num_simulations = 10000\n",
    "for i in np.arange(num_simulations):\n",
    "    new_tvd = simulated_tvd()\n",
    "    tvds = np.append(tvds, new_tvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lec17-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Simulated TVDs (if model is true)'\n",
    "bins = np.arange(0, .05, .005)\n",
    "\n",
    "Table().with_column(title, tvds).hist(bins = bins)\n",
    "print('Observed TVD: ' + str(obsvd_tvd))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
